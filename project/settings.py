"""
Django settings for infraohjelmointi project.

Generated by 'django-admin startproject' using Django 4.1.3.

For more information on this file, see
https://docs.djangoproject.com/en/4.1/topics/settings/

For the full list of settings and their values, see
https://docs.djangoproject.com/en/4.1/ref/settings/
"""
import concurrent.futures
import logging
import os
import socket
import sys
import time
from os import path
from pathlib import Path
from urllib.parse import urlparse

import dj_database_url
import environ

# Initialize logger early for use in settings configuration
logger = logging.getLogger(__name__)

# Build paths inside the project like this: BASE_DIR / 'subdir'.
BASE_DIR = Path(__file__).resolve().parent.parent

# asyncronous application for django event stream
ASGI_APPLICATION = "project.asgi.application"

# Quick-start development settings - unsuitable for production
# See https://docs.djangoproject.com/en/4.1/howto/deployment/checklist/

env = environ.Env(
    DEBUG=(bool, False),
    ALLOWED_HOSTS=(list, ["*"]),
    DATABASE_URL=(str, "sqlite:////tmp/my-tmp-sqlite.db"),
    DJANGO_ADMIN_LANGUAGE=(str, "fi"),
    ALLOWED_CORS_ORIGINS=(list, ["http://localhost:4000", "http://localhost:3000"]),
    STATIC_ROOT=(str, BASE_DIR / "static"),
    STATIC_URL=(str, "/static/"),
    DJANGO_LOG_LEVEL=(str, "INFO"),
    HELSINKI_TUNNISTUS_ISSUER=(
        str,
        "https://tunnistus.test.hel.ninja/auth/realms/helsinki-tunnistus",
    ),
    HELSINKI_TUNNISTUS_AUDIENCE=(str, "infraohjelmointi-api-dev"),
    HELUSERS_BACK_CHANNEL_LOGOUT_ENABLED=(bool, False),
    SOCIAL_AUTH_TUNNISTAMO_SCOPE=(str, "ad_group"),
    TWISTED_MAX_LINE_LENGTH=(int, 32768),
    RESTRICTED_PROGRAMMER_AD_GROUP=(str, "sg_kymp_sso_io_rajoitetut_ohjelmoijat"),
    CACHE_TIMEOUT=(int, 43200),
)

# Read .env file, but environment variables take precedence
# IMPORTANT: docker-compose processes env_file FIRST, then environment: section overrides it
# So when Django starts, environment variables from docker-compose should already be in os.environ
# read_env() with overwrite=False will NOT overwrite existing environment variables
# However, if env_file loaded .env first, we need to ensure environment: values take precedence
if path.exists(".env"):
    # Store original values before reading .env (in case they were set by docker-compose)
    original_redis_url = os.environ.get('REDIS_URL')
    original_db_url = os.environ.get('DATABASE_URL')
    
    # Log what's in environment before reading .env
    logger.info("Environment variables before .env read:")
    for key, value in [('REDIS_URL', original_redis_url), ('DATABASE_URL', original_db_url)]:
        if value:
            safe_value = value.split('@')[-1] if '@' in value else value
            logger.info(f"  {key}={safe_value}")
        else:
            logger.info(f"  {key}=<not set>")
    
    # Read .env file (won't overwrite existing env vars due to overwrite=False)
    env.read_env(".env", overwrite=False)
    
    # Restore original values if they were set (docker-compose environment: takes precedence)
    if original_redis_url:
        os.environ['REDIS_URL'] = original_redis_url
        logger.info(f"Restored REDIS_URL from docker-compose: {original_redis_url.split('@')[-1] if '@' in original_redis_url else original_redis_url}")
    if original_db_url:
        os.environ['DATABASE_URL'] = original_db_url
    
    # Log final values
    logger.info("Environment variables after .env read and restore:")
    for key in ['REDIS_URL', 'DATABASE_URL']:
        value = os.environ.get(key)
        if value:
            safe_value = value.split('@')[-1] if '@' in value else value
            logger.info(f"  {key}={safe_value}")
        else:
            logger.info(f"  {key}=<not set>")

DEBUG = env("DEBUG")
DJANGO_LOG_LEVEL = env("DJANGO_LOG_LEVEL")
# SECURITY WARNING: keep the secret key used in production secret!
SECRET_KEY = env("DJANGO_SECRET_KEY")
ALLOWED_HOSTS = env("ALLOWED_HOSTS")


INSTALLED_APPS = [
    "helusers.apps.HelusersConfig",
    "helusers.apps.HelusersAdminConfig",
    "django.contrib.auth",
    "django.contrib.contenttypes",
    "django.contrib.sessions",
    "django.contrib.messages",
    # disable Djangoâ€™s static file handling during development so that whitenoise can take over
    "whitenoise.runserver_nostatic",
    "django.contrib.staticfiles",
    "simple_history",
    "overrides",
    "corsheaders",
    "rest_framework",
    "rest_framework.authtoken",
    "django_filters",
    "drf_standardized_errors",
    "channels",
    "django_eventstream",
    "social_django",
    "infraohjelmointi_api",
    'drf_yasg',
]

# Application definition
AUTH_USER_MODEL = "infraohjelmointi_api.User"

AUTHENTICATION_BACKENDS = [
    "helusers.tunnistamo_oidc.TunnistamoOIDCAuth",
    "django.contrib.auth.backends.ModelBackend",
]

SOCIAL_AUTH_TUNNISTAMO_SCOPE = env("SOCIAL_AUTH_TUNNISTAMO_SCOPE")
SESSION_SERIALIZER = "django.contrib.sessions.serializers.PickleSerializer"

LOGIN_REDIRECT_URL = "/"
LOGOUT_REDIRECT_URL = "/"


MIDDLEWARE = [
    "corsheaders.middleware.CorsMiddleware",
    "django.middleware.security.SecurityMiddleware",
    # WhiteNoiseMiddleware should be above all and just below SecurityMiddleware
    "whitenoise.middleware.WhiteNoiseMiddleware",
    "django.contrib.sessions.middleware.SessionMiddleware",
    "django.middleware.common.CommonMiddleware",
    "django.middleware.csrf.CsrfViewMiddleware",
    "simple_history.middleware.HistoryRequestMiddleware",
    "django.contrib.auth.middleware.AuthenticationMiddleware",
    "django.contrib.messages.middleware.MessageMiddleware",
    "django.middleware.clickjacking.XFrameOptionsMiddleware",
    "django_grip.GripMiddleware",
]

ROOT_URLCONF = "project.urls"

CORS_ALLOWED_ORIGINS = env("ALLOWED_CORS_ORIGINS")

TEMPLATES = [
    {
        "BACKEND": "django.template.backends.django.DjangoTemplates",
        "DIRS": [
            os.path.join(BASE_DIR, "templates"),
        ],
        "APP_DIRS": True,
        "OPTIONS": {
            "context_processors": [
                "django.template.context_processors.debug",
                "django.template.context_processors.request",
                "django.contrib.auth.context_processors.auth",
                "django.contrib.messages.context_processors.messages",
            ],
        },
    },
]

WSGI_APPLICATION = "project.wsgi.application"


# Database
# https://docs.djangoproject.com/en/4.1/ref/settings/#databases

DATABASES = {"default": dj_database_url.parse(env("DATABASE_URL"))}

HELUSERS_BACK_CHANNEL_LOGOUT_ENABLED = env("HELUSERS_BACK_CHANNEL_LOGOUT_ENABLED")

# These settings specify which authentication server(s) are trusted
# to send back channel logout requests.
OIDC_API_TOKEN_AUTH = {
    # Who we trust to sign the logout tokens. The library will request
    # the public signature keys from standard locations below this URL.
    # Multiple issuers are supported, so this setting can also be a list
    # of strings. Default is https://tunnistamo.hel.fi.
    "ISSUER": env("HELSINKI_TUNNISTUS_ISSUER"),
    # Audience that must be present in the logout token for it to
    # be accepted. Value must be agreed between your SSO service
    # and your application instance. Essentially this allows your
    # application to know that the token is meant to be used with
    # it. Multiple acceptable audiences are supported, so this
    # setting can also be a list of strings. This setting is required.
    "AUDIENCE": env("HELSINKI_TUNNISTUS_AUDIENCE"),
}

from helusers.defaults import SOCIAL_AUTH_PIPELINE


# Password validation
# https://docs.djangoproject.com/en/4.1/ref/settings/#auth-password-validators

AUTH_PASSWORD_VALIDATORS = [
    {
        "NAME": "django.contrib.auth.password_validation.UserAttributeSimilarityValidator",
    },
    {
        "NAME": "django.contrib.auth.password_validation.MinimumLengthValidator",
    },
    {
        "NAME": "django.contrib.auth.password_validation.CommonPasswordValidator",
    },
    {
        "NAME": "django.contrib.auth.password_validation.NumericPasswordValidator",
    },
]


# Internationalization
# https://docs.djangoproject.com/en/4.1/topics/i18n/

LANGUAGE_CODE = env("DJANGO_ADMIN_LANGUAGE")

TIME_ZONE = "Europe/Helsinki"

USE_I18N = True

USE_TZ = True


# Static files (CSS, JavaScript, Images)
# https://docs.djangoproject.com/en/4.1/howto/static-files/


STATIC_URL = env("STATIC_URL")
STATIC_ROOT = env("STATIC_ROOT")


# Default primary key field type
# https://docs.djangoproject.com/en/4.1/ref/settings/#default-auto-field

DEFAULT_AUTO_FIELD = "django.db.models.BigAutoField"

REST_FRAMEWORK = {
    "DEFAULT_AUTHENTICATION_CLASSES": [
        "helusers.oidc.ApiTokenAuthentication",
        'rest_framework.authentication.SessionAuthentication',
        'project.extensions.CustomTokenAuth.CustomTokenAuth',
    ],
}

DRF_STANDARDIZED_ERRORS = {"ENABLE_IN_DEBUG_FOR_UNHANDLED_EXCEPTIONS": False}

LOGGING = {
    "version": 1,
    "disable_existing_loggers": False,
    "formatters": {
        "console": {
            "format": "%(asctime)s %(levelname)s %(pathname)s:%(lineno)d %(message)s",
            "datefmt": "[%d/%b/%Y %H:%M:%S]",
            "()": "project.extensions.ColoredFormatter.ColoredFormatter",
        },
    },
    "handlers": {
        "console": {"class": "logging.StreamHandler", "formatter": "console"},
    },
    "root": {
        "handlers": ["console"],
        "level": env("DJANGO_LOG_LEVEL"),
    },
    "loggers": {
        "infraohjelmointi_api": {
            "handlers": ["console"],
            "level": 1,
            "propagate": False,
        },
    },
}


# Caching framework - Redis for production, LocMemCache as fallback
# Note: logger is already defined at the top of the file

# Get REDIS_URL from environment (docker-compose or .env)
# Also log what's actually in os.environ to debug docker-compose override
redis_url_from_os = os.environ.get('REDIS_URL')
if redis_url_from_os:
    safe_os_url = redis_url_from_os.split('@')[-1] if '@' in redis_url_from_os else redis_url_from_os
    logger.info(f"REDIS_URL from os.environ (before env() call): {safe_os_url}")
else:
    logger.info("REDIS_URL not in os.environ (before env() call)")

REDIS_URL = env('REDIS_URL', default=None)
REDIS_AVAILABLE = False

CACHE_TIMEOUT = env('CACHE_TIMEOUT')


def _is_test_environment() -> bool:
    return 'test' in sys.argv or (sys.argv and 'pytest' in sys.argv[0])


def check_redis_availability(redis_url: str, max_retries: int = 5, initial_delay: float = 0.5) -> bool:
    """Check if Redis is available. Uses thread-based timeout in test environments."""
    parsed = urlparse(redis_url)
    host = parsed.hostname or 'localhost'
    port = parsed.port or 6379
    
    # In test environments, use single attempt with thread-based timeout
    # to handle DNS hanging issues when Redis container is stopped
    if _is_test_environment():
        def try_connect():
            try:
                test_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
                test_socket.settimeout(0.5)
                result = test_socket.connect_ex((host, port))
                test_socket.close()
                return result == 0
            except Exception:
                return False
        
        # Use ThreadPoolExecutor with timeout to handle DNS hanging
        try:
            with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
                future = executor.submit(try_connect)
                return future.result(timeout=1.0)  # 1 second total timeout including DNS
        except (concurrent.futures.TimeoutError, Exception):
            logger.info("Test environment: Redis check timed out or failed")
            return False
    
    # Production: use normal retry logic
    retry_delay = initial_delay
    
    for attempt in range(max_retries):
        try:
            test_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            test_socket.settimeout(2.0)
            result = test_socket.connect_ex((host, port))
            test_socket.close()
            
            if result == 0:
                return True
        except Exception:
            pass
        
        if attempt < max_retries - 1:
            time.sleep(retry_delay)
            retry_delay *= 1.5  # Exponential backoff
    
    return False


def parse_redis_url(redis_url: str) -> dict:
    parsed = urlparse(redis_url)
    config = {
        'host': parsed.hostname or 'localhost',
        'port': parsed.port or 6379,
        'db': int(parsed.path.lstrip('/') or 0) if parsed.path else 0,
    }
    if parsed.password:
        config['password'] = parsed.password
    return config


# Configure Redis if URL is provided
# Skip Redis check for management commands that don't need it (e.g., makemigrations, migrate)
_skip_redis_check_commands = ['makemigrations', 'migrate', 'showmigrations', 'sqlmigrate', 'sqlflush', 'inspectdb', 'collectstatic', 'check']
_skip_redis_check = len(sys.argv) > 1 and sys.argv[1] in _skip_redis_check_commands

if REDIS_URL and not _skip_redis_check:
    # Log the REDIS_URL being used (mask password if present)
    if '@' in REDIS_URL:
        safe_url = REDIS_URL.split('@')[-1]
        logger.info(f"Using REDIS_URL: redis://***@{safe_url}")
    else:
        logger.info(f"Using REDIS_URL: {REDIS_URL}")
    
    # Test Redis connectivity with retries (for Docker Compose startup timing)
    # django-redis will handle actual connection and errors gracefully
    # Use a timeout wrapper to prevent hanging
    try:
        REDIS_AVAILABLE = check_redis_availability(REDIS_URL)
    except Exception as e:
        logger.warning(f"Redis availability check failed: {e}, assuming unavailable")
        REDIS_AVAILABLE = False
    
    if not REDIS_AVAILABLE:
        parsed = urlparse(REDIS_URL)
        host = parsed.hostname or 'localhost'
        port = parsed.port or 6379
        logger.debug(f"Redis not immediately available at {host}:{port}, will attempt connection on first use")
elif REDIS_URL:
    # For management commands, assume Redis is available (will be checked when actually used)
    REDIS_AVAILABLE = True
else:
    REDIS_AVAILABLE = False
    if not _skip_redis_check:
        logger.info("REDIS_URL not configured")

# Configure Redis cache backend if REDIS_URL is provided
# Always configure Redis backend if URL is set, even if not immediately available
# django-redis with IGNORE_EXCEPTIONS will handle connection failures gracefully
# This allows cache to work when Redis becomes available without restart
if REDIS_URL:
    CACHES = {
        "default": {
            "BACKEND": "django_redis.cache.RedisCache",
            "LOCATION": REDIS_URL,
            "OPTIONS": {
                "CLIENT_CLASS": "django_redis.client.DefaultClient",
                "IGNORE_EXCEPTIONS": True,
                "SOCKET_CONNECT_TIMEOUT": 1,
                "SOCKET_TIMEOUT": 1,
                "CONNECTION_POOL_KWARGS": {
                    "max_connections": 10,
                    "retry_on_timeout": False,
                    "socket_connect_timeout": 1,
                    "socket_timeout": 1,
                },
            },
            "KEY_PREFIX": "infraohjelmointi",
            "TIMEOUT": 60 * 60 * 2,  # 2 hour timeout default
        }
    }

    # Configure django-eventstream to use Redis for SSE event storage (fixes IO-725)
    # EVENTSTREAM_REDIS is the correct way to configure Redis for django-eventstream
    # This enables multi-pod event sharing via Redis
    # Only configure EVENTSTREAM_REDIS if Redis is actually available at startup
    # If not available, django-eventstream will fall back to in-memory storage
    # Note: If Redis goes down after startup, EVENTSTREAM_REDIS will still be set,
    # but django-eventstream should handle connection failures gracefully by falling back
    # to in-memory storage (events won't be shared across pods, but app will work)
    if REDIS_AVAILABLE:
        redis_config = parse_redis_url(REDIS_URL)
        EVENTSTREAM_REDIS = {
            'host': redis_config['host'],
            'port': redis_config['port'],
            'db': redis_config['db'],
        }
        if 'password' in redis_config:
            EVENTSTREAM_REDIS['password'] = redis_config['password']
        logger.info("django-eventstream configured to use Redis for multi-pod event sharing")
    else:
        # Don't set EVENTSTREAM_REDIS - django-eventstream will use in-memory storage
        # This allows the app to work without Redis (events won't be shared across pods, but that's OK)
        logger.info("Redis not available - django-eventstream will use in-memory storage (single-pod only)")
    
    safe_url = REDIS_URL.split('@')[-1] if '@' in REDIS_URL else REDIS_URL
    logger.info("Redis cache configured: %s", safe_url)
    if not REDIS_AVAILABLE:
        logger.info("Redis URL configured but not available at startup - cache will attempt connection on first use")
else:
    CACHES = {
        "default": {
            "BACKEND": "django.core.cache.backends.dummy.DummyCache",
        }
    }
    logger.info("Redis not configured - cache disabled (development/local)")

# GRIP proxy configuration (optional - not needed for your scale)
GRIP_URL = env('GRIP_URL', default=None)
if GRIP_URL:
    GRIP_PROXIES = [GRIP_URL]
    logger.info("GRIP proxy configured: %s", GRIP_URL)
else:
    logger.debug("Using direct SSE (no GRIP proxy)")


# Swagger settings
SWAGGER_SETTINGS = {
    'SECURITY_DEFINITIONS': {
        'Basic': {
            'type': 'apiKey',
            'name': 'Authorization',
            'in': 'header',
        }
    },
    'SUPPORTED_SUBMIT_METHODS': ['get'],
    'USE_SESSION_AUTH': False,
}

TWISTED_MAX_LINE_LENGTH = env("TWISTED_MAX_LINE_LENGTH")

def overwrite_twisted_max_line_length(max_line_length):
    """
    Twisted has a default max line length of 16384.
    The following is used to override the default length which is necessary
    for long headers - in the case of helsinki-tunnistus the Authentication
    header can be rather long if the user has many AD groups.
    """
    from twisted.protocols.basic import LineReceiver
    from twisted.web.http import HTTPChannel

    LineReceiver.MAX_LENGTH = max_line_length
    HTTPChannel.totalHeadersSize = max_line_length

overwrite_twisted_max_line_length(TWISTED_MAX_LINE_LENGTH)
